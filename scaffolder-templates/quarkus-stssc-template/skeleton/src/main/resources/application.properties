quarkus.langchain4j.openai.api-key=demo

%dev.quarkus.mailer.mock=false

quarkus.langchain4j.easy-rag.path=src/main/resources/catalog
quarkus.langchain4j.easy-rag.reuse-embeddings.enabled=true

booking.daystostart=14
booking.daystoend=50

# With Podman Desktop
#quarkus.langchain4j.openai.base-url=http://localhost:37681/v1

# With Ollama
#quarkus.langchain4j.openai.base-url=http://localhost:11434/v1
# Configure server to use a specific model
#quarkus.langchain4j.openai.chat-model.model-name=granite3.2
#quarkus.langchain4j.openai.embedding-model.model-name=granite3.2

# With ChatGPT
# Configure openai server to use a specific model
#quarkus.langchain4j.openai.chat-model.model-name=gpt-4o

# Choose a low temperature to minimize hallucination
quarkus.langchain4j.openai.chat-model.temperature=0
# Set timeout to 3 minutes (local LLM can be quite slow)
quarkus.langchain4j.openai.timeout=180s
# Enable logging of both requests and responses
 quarkus.langchain4j.openai.log-requests=true
 quarkus.langchain4j.openai.log-responses=true

quarkus.langchain4j.openai.image-generation.chat-model.model-name=dall-e-3

# You can download the gorilla model from https://huggingface.co/TheBloke/gorilla-7B-GGUF/blob/main/Gorilla-7B.Q4_K_M.gguf and run it with eg. Podman AI Lab:
#quarkus.langchain4j.openai.image-model.base-url=https://api.openai.com/v1/
quarkus.langchain4j.openai.image-model.persist=true
quarkus.langchain4j.openai.image-model.size=1792x1024