# These will be overridden by the ExternalSecret that loads the API key
# QUARKUS_LANGCHAIN4J_OPENAI_API_KEY and QUARKUS_LANGCHAIN4J_OPENAI_BASE_URL
# into the deployment environment
quarkus.langchain4j.openai.api-key=demo
quarkus.langchain4j.openai.base-url=http://localhost:37681/v1

# Used by the EasyRAG example
# In dev mode, use the filesystem path for hot reload
%dev.quarkus.langchain4j.easy-rag.path=src/main/resources/catalog/
# In prod/container, use the classpath (resources are packaged in the JAR)
quarkus.langchain4j.easy-rag.path=catalog/
quarkus.langchain4j.easy-rag.reuse-embeddings.enabled=true

# Target a specific model from our LiteLLM server
quarkus.langchain4j.openai.chat-model.model-name=granite-3-2-8b-instruct
quarkus.langchain4j.openai.embedding-model.model-name=nomic-embed-text-v1-5

# Using a low temperature to minimize hallucination
quarkus.langchain4j.openai.chat-model.temperature=0

# During local development, the local LLM can be quite slow,
# so we set a timeout of 3 minutes to wait for the response
quarkus.langchain4j.openai.timeout=180s

# Enable logging of both requests and responses
quarkus.langchain4j.openai.log-requests=true
quarkus.langchain4j.openai.log-responses=true

# Used by the BookingService to mock the booking details
booking.daystostart=14
booking.daystoend=50